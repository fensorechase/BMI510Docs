% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bmi510-template.R
\name{precision}
\alias{precision}
\title{Calculate precision metric for predicted and truth labels}
\usage{
precision(pred, truth)
}
\arguments{
\item{pred}{A vector of predicted labels (0 or 1)}

\item{truth}{A vector of true labels (0 or 1)}
}
\value{
The precision metric as a single numeric value
}
\description{
This function calculates the precision metric for a binary classification problem
based on the predicted labels and the true labels. Precision measures the proportion
of true positive predictions out of all positive predictions.
}
\examples{
pred <- c(1, 0, 0, 1, 1, 0, 1, 0)
truth <- c(1, 0, 1, 0, 1, 0, 1, 0)
precision(pred, truth)

}
