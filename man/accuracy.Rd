% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bmi510-template.R
\name{accuracy}
\alias{accuracy}
\title{Calculate accuracy metric based on predicted and truth labels}
\usage{
accuracy(pred, truth)
}
\arguments{
\item{pred}{A vector of predicted labels.}

\item{truth}{A vector of true labels.}
}
\value{
A numeric value representing the accuracy of the predictions.
}
\description{
Calculates the accuracy metric as the proportion of correct predictions
over the total number of predictions, based on comparing predicted and
truth labels.
}
\examples{
# Binary classification example
pred <- c(0, 1, 1, 0, 1)
truth <- c(1, 1, 0, 0, 1)
accuracy(pred, truth)
# Output: 0.6

}
